{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Dependencies:\n",
    "#   - numpy\n",
    "#   - pandas\n",
    "#   - tensorflow\n",
    "#   - stellargraph\n",
    "\n",
    "import numpy as np  # Linear algebra routines;\n",
    "import pandas as pd # Data-frame processing, CSV file I/O (e.g. pd.read_csv);\n",
    "\n",
    "# Load the StellarGraph library;\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph.mapper import FullBatchLinkGenerator\n",
    "from stellargraph.layer import GCN, LinkEmbedding\n",
    "from stellargraph.utils import plot_history\n",
    "from tensorflow import keras \n",
    "\n",
    "# Used to load files;\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the \"./input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory;\n",
    "print(os.listdir(\"./input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output;\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# A list of utility functions used below to manipulate/clean data and compute accuracy metrics;\n",
    "\n",
    "# Preprocess and clean the PPI dataset;\n",
    "def build_dataframe(input_data: pd.DataFrame, col_name: str, preserve_int_col_name=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given an input DataFrame and a column name, return a new DataFrame in which the column has been cleaned.\n",
    "    Used to transform features and labels columns from \"0;1;1;0\" to [0, 1, 1, 0]\n",
    "    \"\"\"\n",
    "    vertices_dict = []\n",
    "    for i, row_i in input_data.iterrows():\n",
    "        features = [int(float(x)) for x in row_i[f\"{col_name}s\"].split(\";\")]\n",
    "        \n",
    "        new_v = {\"id\": i}\n",
    "        for j, f in enumerate(features):\n",
    "            new_v[j if preserve_int_col_name else f\"{col_name}_{j}\"] = f\n",
    "        vertices_dict += [new_v]\n",
    "    res_df = pd.DataFrame(vertices_dict)\n",
    "    return res_df.set_index(\"id\")\n",
    "\n",
    "# Compute the F1 score from 2 vectors of binary labels (0, 1), (ground truth and predictions).\n",
    "# Taken as-is from old Keras source code, before it got removed;\n",
    "def f1_score(y_true, y_pred) -> float:\n",
    "    true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))\n",
    "    predicted_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + keras.backend.epsilon())\n",
    "    recall = true_positives / (possible_positives + keras.backend.epsilon())\n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + keras.backend.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph name;\n",
    "graph_name = \"ppi\"\n",
    "\n",
    "# Read vertex data;\n",
    "vertices_path = f\"./input/{graph_name}_v.csv\"\n",
    "vertices = pd.read_csv(vertices_path, sep=\",\", index_col=\"id\")\n",
    "vertices.drop([\"dataset\"], axis=1, inplace=True)\n",
    "vertices = build_dataframe(vertices, \"feature\")\n",
    "vertices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read edges data (training data);\n",
    "edge_path = f\"./input/{graph_name}_e_train.csv\"\n",
    "edges = pd.read_csv(edge_path, sep=\",\", index_col=None)\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build input graph from vertices and edges (training data) dataframes;\n",
    "ppi_graph = StellarGraph(\n",
    "    nodes={\"protein\": vertices},\n",
    "    edges={\"interaction\": edges},\n",
    "    source_column=\"source\",\n",
    "    target_column=\"dest\"\n",
    "    )\n",
    "print(ppi_graph.info())\n",
    "\n",
    "# Multigraph: there can be multiple edges between vertices -> Hint: most likely noise, it does not make much sense to have multiple edges here;\n",
    "# Vertex features: float32 -> Maybe it should be int/bool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the input graph into a train and validation graphs \n",
    "edge_splitter_validation = EdgeSplitter(ppi_graph)\n",
    "\n",
    "# Randomly sample a fraction p=0.1 of all positive links, and same number of negative links, from ppi_graph, \n",
    "# Obtain the reduced graph graph_valid with the sampled links removed\n",
    "# edges_validation and validation are employed as ground truth for testing the model;\n",
    "graph_validation, edges_validation, labels_validation = edge_splitter_validation.train_test_split(\n",
    "    p=0.1, method=\"global\", keep_connected=True, seed=42\n",
    ")\n",
    "print(graph_validation.info())\n",
    "\n",
    "# \"global\" -> pick random pairs of vertices to create fake edges (\"negative samples\")\n",
    "# \"keep_connected\" -> Don't remove edges that would disconnect graphs\n",
    "# p=0.1 -> remove 10% of edges\n",
    "\n",
    "# graph_validation -> new graph with 10% of edges removed, we use it to create the training set\n",
    "# edges_validation -> list of edges used for testing. 50% are real, 50% are fake\n",
    "# labels_validation -> labels that identify real/fake edges in edges_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe to visualize the real/fake edges (not used in the training);\n",
    "edges_validation_sources = [edges_validation[i][0] for i in range(0, len(edges_validation))]\n",
    "edges_validation_dests = [edges_validation[i][1] for i in range(0, len(edges_validation))]\n",
    "edges_validation_df = pd.DataFrame(list(zip(edges_validation_sources, edges_validation_dests, labels_validation)), columns=[\"source\", \"dest\", \"label\"])\n",
    "print(edges_validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a dataset for training, by creating again some fake edges;\n",
    "# Note: by passing the original \"ppi_graph\" as well, we guarantee that real edges \n",
    "#   that are no longer present in \"graph_validation\" cannot be created as fake edges.\n",
    "# This avoids teaching the model that a real edge should be classified as fake.\n",
    "# Is this a leak? Probably not, but think about it (and test your hypotheses)!\n",
    "edge_splitter_train = EdgeSplitter(graph_validation, ppi_graph)\n",
    "\n",
    "# Same as before, create fake edges to use during the training;\n",
    "graph_train, edges_train, labels_train = edge_splitter_train.train_test_split(\n",
    "    p=0.1, method=\"global\", keep_connected=True, seed=42\n",
    ")\n",
    "\n",
    "# Note: you might want to do this step again (at the very beginning) to create a test set not employed during training;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training dataframe for explicit visualization;\n",
    "edges_train_sources = [edges_train[i][0] for i in range(0, len(edges_train))]\n",
    "edges_train_dests = [edges_train[i][1] for i in range(0, len(edges_train))]\n",
    "edges_train_df = pd.DataFrame(list(zip(edges_train_sources, edges_train_dests, labels_train)), columns=[\"source\", \"dest\", \"label\"])\n",
    "print(edges_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator on graph_train and make an iterator over the training links.\n",
    "# This class creates the data fed to the model during the training.\n",
    "# This is used during the training to extract from the graph all the required information (e.g. vertex features given an edge).\n",
    "# \"gcn\" is used to specify how data are preprocessed. Depending on your model of choice, you might need a different option: \n",
    "#   https://stellargraph.readthedocs.io/en/stable/api.html#stellargraph.mapper.FullBatchLinkGenerator\n",
    "train_gen = FullBatchLinkGenerator(graph_train, method=\"gcn\")\n",
    "train_flow = train_gen.flow(edges_train, labels_train)\n",
    "\n",
    "# Same thing, create a LinkGenerator to be used for validation;\n",
    "validation_gen = FullBatchLinkGenerator(graph_validation, method=\"gcn\")\n",
    "validation_flow = validation_gen.flow(edges_validation, labels_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple GCN model.\n",
    "# We specify the generator used in the training here!\n",
    "gcn = GCN(\n",
    "    layer_sizes=[16, 16], activations=[\"relu\", \"relu\"], generator=train_gen, dropout=0.3\n",
    ")\n",
    "\n",
    "# Expose input and output tensors of the GCN model for link prediction;\n",
    "x_inp, x_out = gcn.in_out_tensors()\n",
    "\n",
    "# Create the final link embedding layer: \n",
    "# - it takes a pair of vertex embeddings produced by the GCN model, \n",
    "# - applies a binary operator (ip = inner product) to produce the corresponding link embedding,\n",
    "# - passes it through a dense layer (if method!=\"ip\") to obtain the wanted embedding dimension\n",
    "prediction = LinkEmbedding(activation=\"relu\", method=\"ip\")(x_out)\n",
    "\n",
    "# Reshape the predictions from (X, 1) to (X,) to match the shape of targets;\n",
    "prediction = keras.layers.Reshape((-1,))(prediction)\n",
    "\n",
    "# Stack the GCN and prediction layers into a Keras model;\n",
    "model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "\n",
    "# Compile the model, specifying the hyperparameters;\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=0.005),\n",
    "    loss=keras.losses.binary_crossentropy,               # We do binary classification;\n",
    "    metrics=[keras.metrics.BinaryAccuracy(), f1_score],  # Also measure binary accuracy and F1 score;\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the initial (untrained) model on the train and validation sets, to get baseline scores;\n",
    "init_train_metrics = model.evaluate(train_flow)\n",
    "init_valid_metrics = model.evaluate(validation_flow)\n",
    "\n",
    "print(\"\\nTrain Set Metrics of the initial (untrained) model:\")\n",
    "for name, val in zip(model.metrics_names, init_train_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "\n",
    "print(\"\\nValidation Set Metrics of the initial (untrained) model:\")\n",
    "for name, val in zip(model.metrics_names, init_valid_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "\n",
    "# If you get F1=0, it's likely that everything is predicted as false and Recall is 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of training epochs;\n",
    "epochs = 100\n",
    "\n",
    "# Train the model (here, we specify the validation set);\n",
    "history = model.fit(\n",
    "    train_flow, epochs=epochs, validation_data=validation_flow, verbose=2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training history\n",
    "plot_history(history)\n",
    "\n",
    "# Accuracy oscillates, and train and validation are close -> This indicates a high learning rate, and an incomplete training (underfitting);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on the train and validation sets: \n",
    "train_metrics = model.evaluate(train_flow)\n",
    "validation_metrics = model.evaluate(validation_flow)\n",
    "\n",
    "print(\"\\nTrain Set Metrics of the trained model:\")\n",
    "for name, val in zip(model.metrics_names, train_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "\n",
    "print(\"\\nValidation Set Metrics of the trained model:\")\n",
    "for name, val in zip(model.metrics_names, validation_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read edges data (test data)\n",
    "edge_path = f\"./input/{graph_name}_e_test.csv\"\n",
    "edges_test = pd.read_csv(edge_path, sep=\",\", index_col=None)\n",
    "\n",
    "# Delete duplicated edges, if they exist;\n",
    "edges_test = edges_test.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Extract numpy arrays for test examples;\n",
    "examples_test = edges_test.to_numpy()\n",
    "\n",
    "edges_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator on ppi_graph and make an iterator over the test links;\n",
    "test_gen = FullBatchLinkGenerator(ppi_graph, method=\"gcn\")\n",
    "test_flow = test_gen.flow(examples_test)\n",
    "\n",
    "# Compute the predictions for the edges in the test set;\n",
    "y_pred = model.predict(test_flow)\n",
    "y_pred = keras.backend.round(keras.backend.clip(y_pred, 0, 1)).numpy()\n",
    "\n",
    "# Attach the predictions to the test dataframe, then save it as the final output file.\n",
    "# The output file should be \"id,label\", where \"id\" is \"source_dest\";\n",
    "y_pred_df = pd.DataFrame(np.transpose(y_pred).astype(int), columns=[\"label\"])\n",
    "output = pd.concat([edges_test, y_pred_df], axis=1)\n",
    "output[\"id\"] = output[\"source\"].astype(str) + \"_\" + output[\"dest\"].astype(str)\n",
    "output[[\"id\", \"label\"]].to_csv(f\"sample_{graph_name}_predictions.csv\", index=False)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "interpreter": {
   "hash": "0b91dc54d59c6a2f375021dc1af6a62a8eea443f7dff80b0c4836078a19fe2a3"
  },
  "kernelspec": {
   "display_name": "Python [conda env:GraphML] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
